{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from model import CNNSentence\n",
    "from cnndata import DATA, getVectors, clean_str\n",
    "\n",
    "def inference(model, data, mode='test'):\n",
    "    \"\"\"\n",
    "    Runs testing for a given model\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : TYPE\n",
    "        A trained torch classification model.\n",
    "    batch : object of class DATA\n",
    "    mode : str\n",
    "        Defines, whether to run the test on dev set or test set. The default is 'test'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : loss for the dataset\n",
    "    acc : accuracy of model\n",
    "    preds: torch tensor of shape [n, 2] with predictions and labels\n",
    "\n",
    "    \"\"\"\n",
    "    #define loss and prep model for evaluation\n",
    "\n",
    "    return pred\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        with open(f'data/cnn.txt', 'r') as f:\n",
    "            arg_dict = json.load(f)\n",
    "        self.__dict__ = arg_dict\n",
    "\n",
    "def load_model(args, data, vectors):\n",
    "    \"\"\"\n",
    "    Helper function to load model from file    \n",
    "    \"\"\"\n",
    "    model_path = f'data/cnn.pt'\n",
    "    model = CNNSentence(args, data, vectors)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model\n",
    "def predict(model, data, sents):\n",
    "        indexed = [[data.TEXT.vocab.stoi[t] for t in sent] for sent in sents]\n",
    "        indexed = [[indx + [0] * (70 - len(indx))] for indx in indexed]\n",
    "        \n",
    "        tensor = torch.LongTensor(indexed).to('cpu')\n",
    "        tensor = tensor.squeeze(1)\n",
    "        pred = model(tensor)\n",
    "        return pred.max(1)\n",
    "\n",
    "def get_preds(sents):\n",
    "    labels = [\"joy\",\"sadness\",\"anger\",\"fear\",\"love\",\"surprise\"]\n",
    "    args = Args()\n",
    "    sents = [clean_str(sent).split() for sent in sents]\n",
    "    \n",
    "    data = DATA()\n",
    "    vectors = getVectors(args, data)\n",
    "    setattr(args, 'word_vocab_size', len(data.TEXT.vocab))\n",
    "    setattr(args, 'class_size', 6)\n",
    "    model = load_model(args, data, vectors)\n",
    "    model.eval()\n",
    "\n",
    "    preds = predict(model, data, sents)\n",
    "    return [labels[pred] for pred in preds[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['I am so very sad and happy at the same time','What is going on out here?',\n",
    "            'You don\\'t need to say it', 'I find this theme weird', 'FFu bitch']\n",
    "preds = get_preds(val.txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
